import weaviate
from sentence_transformers import SentenceTransformer
from weaviate.classes.query import Filter, QueryReference
from typing import Dict, List, Any, Optional

class Rechercheur:
    def __init__(self, client: weaviate.WeaviateClient, model: SentenceTransformer, maxdoc: int = 2, maxchnunks: int = 2):
        self.client = client
        self.model = model
        self.documents = client.collections.get("Document")
        self.chunks = client.collections.get("Chunk")
        self.maxdoc = maxdoc
        self.maxchnunks = maxchnunks
    
    def recherche_complete(self, search_input: Dict[str, Any]) -> Dict[str, Any]:
        """
        Recherche complÃ¨te en 3 phases
        """
        print(f"ğŸš€ DÃ©marrage de la recherche en 3 phases (max {self.maxdoc} docs, {self.maxchnunks} chunks)...")
        
        # Phase 1: Filtres exacts
        documents_filtres = self._phase1_filtres_exacts(search_input)
        if not documents_filtres:
            return {"documents": [], "chunks": [], "message": "Aucun document trouvÃ© avec les filtres exacts"}
        
        # Phase 2: Recherche hybride sur documents
        documents_candidats = self._phase2_recherche_hybride_documents(documents_filtres, search_input)
        if not documents_candidats:
            return {"documents": [], "chunks": [], "message": "Aucun document candidat trouvÃ©"}
        
        # Phase 3: Recherche hybride sur chunks
        chunks_finaux = self._phase3_recherche_hybride_chunks(documents_candidats, search_input)
        
        return {
            "documents": documents_candidats,
            "chunks": chunks_finaux,
            "message": f"TrouvÃ© {len(documents_candidats)} document(s) et {len(chunks_finaux)} chunk(s)"
        }
    
    def _phase1_filtres_exacts(self, search_input: Dict[str, Any]) -> List[Any]:
        """
        Phase 1: Filtres exacts sur title, client, document_type
        """
        print("ğŸ“‹ Phase 1: Application des filtres exacts...")
        
        try:
            # Construction des filtres exacts
            filters = []
            
            if search_input.get("title"):
                title_values = search_input["title"]
                for title in title_values:
                    filters.append(Filter.by_property("title").equal(title))
            
            if search_input.get("client"):
                client_values = search_input["client"]
                for client in client_values:
                    filters.append(Filter.by_property("client").equal(client))
            
            if search_input.get("document_type"):
                doc_type_values = search_input["document_type"]
                for doc_type in doc_type_values:
                    filters.append(Filter.by_property("document_type").equal(doc_type))
            
            # Application des filtres
            if filters:
                # Combine avec OR pour chaque type, puis AND entre les types
                combined_filter = filters[0]
                for f in filters[1:]:
                    combined_filter = combined_filter | f
                
                response = self.documents.query.fetch_objects(
                    where=combined_filter,
                    limit=50  # Large limite pour la phase 2
                )
            else:
                # Pas de filtres, prendre tous les documents
                response = self.documents.query.fetch_objects(limit=50)
            
            documents = response.objects
            print(f"   âœ… {len(documents)} document(s) aprÃ¨s filtrage exact")
            return documents
            
        except Exception as e:
            print(f"   âš ï¸ Erreur filtres exacts, fallback sans filtres: {e}")
            # Fallback: rÃ©cupÃ©ration manuelle avec filtrage
            return self._fallback_filtrage_manuel(search_input)
    
    def _fallback_filtrage_manuel(self, search_input: Dict[str, Any]) -> List[Any]:
        """
        Filtrage manuel en cas d'Ã©chec des filtres Weaviate
        """
        try:
            response = self.documents.query.fetch_objects(limit=50)
            all_docs = response.objects
            
            filtered_docs = []
            for doc in all_docs:
                match = True
                
                # VÃ©rifie title
                if search_input.get("title"):
                    doc_title = doc.properties.get("title", "")
                    if not any(title in doc_title for title in search_input["title"]):
                        match = False
                
                # VÃ©rifie client
                if match and search_input.get("client"):
                    doc_client = doc.properties.get("client", "")
                    if doc_client not in search_input["client"]:
                        match = False
                
                # VÃ©rifie document_type
                if match and search_input.get("document_type"):
                    doc_type = doc.properties.get("document_type", "")
                    if doc_type not in search_input["document_type"]:
                        match = False
                
                if match:
                    filtered_docs.append(doc)
            
            print(f"   âœ… {len(filtered_docs)} document(s) aprÃ¨s filtrage manuel")
            return filtered_docs
            
        except Exception as e:
            print(f"   âŒ Erreur filtrage manuel: {e}")
            return []
    
    def _phase2_recherche_hybride_documents(self, documents_filtres: List[Any], search_input: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        Phase 2: Recherche hybride sur documents avec summary, keywords, sector
        """
        print("ğŸ” Phase 2: Recherche hybride sur documents...")
        
        # Construction de la requÃªte hybride
        query_parts = []
        
        if search_input.get("summary"):
            query_parts.append(search_input["summary"])
        
        if search_input.get("keywords"):
            query_parts.extend(search_input["keywords"])
        
        if search_input.get("sector"):
            query_parts.extend(search_input["sector"])
        
        if not query_parts:
            # Pas de critÃ¨res hybrides, prendre les premiers documents filtrÃ©s
            print(f"   âš ï¸ Pas de critÃ¨res hybrides, sÃ©lection des {self.maxdoc} premiers documents")
            return self._format_documents(documents_filtres[:self.maxdoc])
        
        query_text = " ".join(query_parts)
        print(f"   ğŸ¯ RequÃªte vectorielle: '{query_text[:100]}...'")
        
        try:
            # Encode manuellement la requÃªte puisque pas de vectorizer automatique
            query_vector = self.model.encode(query_text)
            
            # Recherche vectorielle manuelle dans les documents
            response = self.documents.query.near_vector(
                near_vector=query_vector.tolist(),
                limit=self.maxdoc * 3  # Plus large pour filtrer ensuite
            )
            
            hybrid_docs = response.objects
            
            # Filtrer pour ne garder que les documents de la phase 1
            doc_ids_phase1 = [str(doc.uuid) for doc in documents_filtres]
            documents_candidats = []
            
            for doc in hybrid_docs:
                if str(doc.uuid) in doc_ids_phase1:
                    documents_candidats.append(doc)
                    if len(documents_candidats) >= self.maxdoc:
                        break
            
            # Si pas assez de rÃ©sultats hybrides, complÃ©ter avec les documents filtrÃ©s
            if len(documents_candidats) < self.maxdoc:
                for doc in documents_filtres:
                    if str(doc.uuid) not in [str(d.uuid) for d in documents_candidats]:
                        documents_candidats.append(doc)
                        if len(documents_candidats) >= self.maxdoc:
                            break
            
            print(f"   âœ… {len(documents_candidats)} document(s) candidat(s) sÃ©lectionnÃ©(s)")
            return self._format_documents(documents_candidats)
            
        except Exception as e:
            print(f"   âš ï¸ Erreur recherche vectorielle documents: {e}")
            # Fallback: sÃ©lectionner les premiers documents filtrÃ©s
            return self._format_documents(documents_filtres[:self.maxdoc])
    
    def _phase3_recherche_hybride_chunks(self, documents_candidats: List[Dict[str, Any]], search_input: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        Phase 3: Recherche hybride dans les chunks avec la query
        """
        print("ğŸ¯ Phase 3: Recherche vectorielle dans les chunks...")
        
        query = search_input.get("query", "")
        if not query:
            print("   âš ï¸ Pas de query fournie")
            return []
        
        print(f"   ğŸ¯ Query: '{query}'")
        
        # IDs des documents candidats
        doc_ids = [doc["id"] for doc in documents_candidats]
        
        try:
            # Encode manuellement la query puisque pas de vectorizer automatique
            query_vector = self.model.encode(query)
            
            # Recherche vectorielle manuelle dans les chunks
            response = self.chunks.query.near_vector(
                near_vector=query_vector.tolist(),
                limit=self.maxchnunks * 5  # Plus large pour filtrer ensuite
            )
            
            all_chunks = response.objects
            print(f"   ğŸ“Š {len(all_chunks)} chunk(s) trouvÃ©(s) au total")
            print(f"   ğŸ¯ Documents candidats IDs: {doc_ids}")
            
            # Debug: afficher la structure du premier chunk
            if len(all_chunks) > 0:
                first_chunk = all_chunks[0]
                print(f"   ğŸ” Structure du premier chunk:")
                print(f"      - UUID: {first_chunk.uuid}")
                print(f"      - Properties: {list(first_chunk.properties.keys()) if first_chunk.properties else 'None'}")
                print(f"      - Has references attr: {hasattr(first_chunk, 'references')}")
                if hasattr(first_chunk, 'references'):
                    print(f"      - References: {first_chunk.references}")
                    if first_chunk.references:
                        print(f"      - References keys: {list(first_chunk.references.keys())}")
            
            # Filtrer pour ne garder que les chunks des documents candidats
            chunks_filtres = []
            for i, chunk in enumerate(all_chunks):
                try:
                    print(f"   ğŸ” Chunk {i+1}: analyse...")
                    
                    # MÃ©thode 1: VÃ©rifier les rÃ©fÃ©rences
                    ref_doc_id = None
                    if hasattr(chunk, 'references') and chunk.references:
                        if chunk.references.get("ofDocument"):
                            if hasattr(chunk.references["ofDocument"], 'objects') and chunk.references["ofDocument"].objects:
                                ref_doc_id = str(chunk.references["ofDocument"].objects[0].uuid)
                                print(f"      âœ… RÃ©fÃ©rence trouvÃ©e: {ref_doc_id}")
                            else:
                                print(f"      âš ï¸ ofDocument existe mais pas d'objects")
                        else:
                            print(f"      âŒ Pas de rÃ©fÃ©rence ofDocument")
                    else:
                        print(f"      âŒ Pas de rÃ©fÃ©rences du tout")
                    
                    # Si on a trouvÃ© une rÃ©fÃ©rence valide
                    if ref_doc_id and ref_doc_id in doc_ids:
                        chunks_filtres.append(chunk)
                        print(f"      âœ… Chunk ajoutÃ© ! ({len(chunks_filtres)}/{self.maxchnunks})")
                        if len(chunks_filtres) >= self.maxchnunks:
                            break
                    elif ref_doc_id:
                        print(f"      âŒ Document ID '{ref_doc_id}' non dans candidats {doc_ids}")
                        
                except Exception as ref_error:
                    print(f"      âš ï¸ Erreur rÃ©fÃ©rence chunk {i+1}: {ref_error}")
                    continue
            
            print(f"   âœ… {len(chunks_filtres)} chunk(s) pertinent(s) trouvÃ©(s)")
            
            # Si aucun chunk trouvÃ© avec filtrage, essai sans filtrage
            if len(chunks_filtres) == 0 and len(all_chunks) > 0:
                print(f"   ğŸ”„ Fallback: prise des {self.maxchnunks} premiers chunks sans filtrage")
                chunks_filtres = all_chunks[:self.maxchnunks]
            
            return self._format_chunks(chunks_filtres)
            
        except Exception as e:
            print(f"   âš ï¸ Erreur recherche vectorielle chunks: {e}")
            # Fallback: recherche vectorielle simple
            return self._fallback_chunks_vectoriel(doc_ids, query)
    
    def _fallback_chunks_vectoriel(self, doc_ids: List[str], query: str) -> List[Dict[str, Any]]:
        """
        Fallback: recherche vectorielle simple dans les chunks
        """
        try:
            query_vector = self.model.encode(query)
            
            response = self.chunks.query.near_vector(
                near_vector=query_vector.tolist(),
                limit=self.maxchnunks * 5
            )
            
            all_chunks = response.objects
            
            # Filtrage manuel
            chunks_filtres = []
            for chunk in all_chunks:
                try:
                    if hasattr(chunk, 'references') and chunk.references.get("ofDocument"):
                        ref_doc_id = str(chunk.references["ofDocument"].objects[0].uuid)
                        if ref_doc_id in doc_ids:
                            chunks_filtres.append(chunk)
                            if len(chunks_filtres) >= self.maxchnunks:
                                break
                except:
                    continue
            
            print(f"   âœ… Fallback vectoriel: {len(chunks_filtres)} chunk(s)")
            return self._format_chunks(chunks_filtres)
            
        except Exception as e:
            print(f"   âŒ Erreur fallback chunks: {e}")
            return []
    
    def _format_documents(self, docs: List[Any]) -> List[Dict[str, Any]]:
        """Formate les documents pour la rÃ©ponse"""
        formatted = []
        for doc in docs:
            formatted.append({
                "id": str(doc.uuid),
                "title": doc.properties.get("title", ""),
                "client": doc.properties.get("client", ""),
                "document_type": doc.properties.get("document_type", ""),
                "summary": doc.properties.get("summary", ""),
                "keywords": doc.properties.get("keywords", []),
                "sector": doc.properties.get("sector", []),
                "budget": doc.properties.get("budget", 0),
                "date": doc.properties.get("date", "")
            })
        return formatted
    
    def _format_chunks(self, chunks: List[Any]) -> List[Dict[str, Any]]:
        """Formate les chunks pour la rÃ©ponse"""
        formatted = []
        for chunk in chunks:
            doc_id = "unknown"
            try:
                if hasattr(chunk, 'references') and chunk.references.get("ofDocument"):
                    doc_id = str(chunk.references["ofDocument"].objects[0].uuid)
            except:
                pass
            
            formatted.append({
                "id": str(chunk.uuid),
                "contenu": chunk.properties.get("contenu", ""),
                "page": chunk.properties.get("page", 0),
                "indexchunk": chunk.properties.get("indexchunk", 0),
                "document_id": doc_id
            })
        return formatted

# Fonction principale pour utiliser le module
def recherche(search_input: Dict[str, Any], maxdoc: int = 2, maxchnunks: int = 2, model: SentenceTransformer = None) -> Dict[str, Any]:
    """
    Point d'entrÃ©e principal du module de recherche
    
    Args:
        search_input: JSON avec les critÃ¨res de recherche
        maxdoc: Nombre maximum de documents Ã  retourner (dÃ©faut: 2)
        maxchnunks: Nombre maximum de chunks Ã  retourner (dÃ©faut: 2)
        model: ModÃ¨le SentenceTransformer pour la vectorisation
    """
    client = None
    try:
        # VÃ©rification du modÃ¨le
        if model is None:
            return {"error": "Le modÃ¨le SentenceTransformer est requis"}
        
        # Connexion Ã  Weaviate
        client = weaviate.connect_to_local(
            host="localhost",
            port=8080,
            grpc_port=50051,
        )
        
        if not client.is_ready():
            return {"error": "Weaviate n'est pas disponible"}
        
        # CrÃ©ation du rechercheur avec le modÃ¨le fourni
        rechercheur = Rechercheur(client, model, maxdoc, maxchnunks)
        
        # ExÃ©cution de la recherche
        results = rechercheur.recherche_complete(search_input)
        
        return results
        
    except Exception as e:
        return {"error": f"Erreur lors de la recherche: {e}"}
    finally:
        if client:
            client.close()

# Test du module
if __name__ == "__main__":
    # Chargement du modÃ¨le Ã  l'extÃ©rieur
    print("ğŸ“¥ Chargement du modÃ¨le d'embeddings...")
    model = SentenceTransformer('./models/intfloat_multilingual-e5-small')
    print("âœ… ModÃ¨le chargÃ©.")
    
    search_input = {
        "title": ["Offre Client ABC"],
        "document_type": ["offre"],
        "client": ["Client ABC"],
        "summary": "RÃ©sumÃ© de l'offre",
        "keywords": ["Proposition de Solution Technique", "SociÃ©tÃ© MarocData"],
        "sector": ["Consulting"],
        "query": "donner moi le Planning PrÃ©visionnel pour ce projet de l'analyse vers le DÃ©ploiement"
    }
    
    print("ğŸ§ª Test du module de recherche...")
    results = recherche(search_input, maxdoc=2, maxchnunks=2, model=model)
    
    if "error" in results:
        print(f"âŒ Erreur: {results['error']}")
    else:
        print(f"\nğŸ‰ RÃ©sultats:")
        print(f"ğŸ“‹ Documents trouvÃ©s: {len(results['documents'])}")
        print(f"ğŸ“ Chunks trouvÃ©s: {len(results['chunks'])}")
        print(f"ğŸ’¬ Message: {results['message']}")
        
        for i, doc in enumerate(results['documents']):
            print(f"\nğŸ“‹ Document {i+1}: {doc['title']}")
        
        for i, chunk in enumerate(results['chunks']):
            print(f"\nğŸ“ Chunk {i+1}: {chunk['contenu'][:1000]}...")